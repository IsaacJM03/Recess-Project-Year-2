{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95335f4a",
   "metadata": {},
   "source": [
    "# Eye Disease Dataset Analysis\n",
    "\n",
    "### Dataset Overview\n",
    "This dataset contains eye disease images categorized into:\n",
    "- Cataract\n",
    "- Diabetic Retinopathy  \n",
    "- Glaucoma\n",
    "- Normal (healthy eyes)\n",
    "\n",
    "**Simplified Approach:** Combined data exploration, missing value analysis, and handling strategy into streamlined workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb25f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a528b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1-3: Complete Dataset Analysis & Missing Data Handling\n",
    "dataset_path = \"dataset\"\n",
    "categories = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "\n",
    "# Quick analysis of all categories\n",
    "results = []\n",
    "for category in categories:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Count valid vs corrupted images\n",
    "    valid_count = 0\n",
    "    for img_file in image_files:\n",
    "        try:\n",
    "            with Image.open(os.path.join(category_path, img_file)) as img:\n",
    "                img.verify()\n",
    "            valid_count += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    corrupted = len(image_files) - valid_count\n",
    "    missing_pct = (corrupted / len(image_files) * 100) if image_files else 0\n",
    "    \n",
    "    results.append({\n",
    "        'Category': category,\n",
    "        'Total_Files': len(image_files),\n",
    "        'Valid_Images': valid_count,\n",
    "        'Corrupted': corrupted,\n",
    "        'Missing_%': missing_pct,\n",
    "        'Action': 'Remove' if missing_pct < 5 else 'Investigate'\n",
    "    })\n",
    "\n",
    "# Create summary DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "total_images = df['Total_Files'].sum()\n",
    "total_corrupted = df['Corrupted'].sum()\n",
    "overall_missing = (total_corrupted / total_images * 100)\n",
    "\n",
    "print(\"ðŸ“Š DATASET ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nðŸ” OVERALL STATISTICS:\")\n",
    "print(f\"Total images: {total_images:,}\")\n",
    "print(f\"Corrupted images: {total_corrupted}\")\n",
    "print(f\"Missing data: {overall_missing:.2f}%\")\n",
    "print(f\"Recommended action: {'Simple removal' if overall_missing < 5 else 'Detailed investigation'}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# 1. Dataset distribution\n",
    "ax1.bar(df['Category'], df['Valid_Images'], color='lightgreen', alpha=0.8)\n",
    "ax1.set_title('Valid Images by Category')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Missing data percentage\n",
    "ax2.bar(df['Category'], df['Missing_%'], color='coral', alpha=0.8)\n",
    "ax2.set_title('Missing Data %')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.axhline(y=5, color='red', linestyle='--', label='5% threshold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Data quality pie chart\n",
    "valid_total = df['Valid_Images'].sum()\n",
    "ax3.pie([valid_total, total_corrupted], labels=['Valid', 'Corrupted'], \n",
    "        autopct='%1.1f%%', colors=['lightgreen', 'coral'])\n",
    "ax3.set_title('Overall Data Quality')\n",
    "\n",
    "# 4. Category proportions\n",
    "ax4.pie(df['Valid_Images'], labels=df['Category'], autopct='%1.1f%%')\n",
    "ax4.set_title('Dataset Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Tasks 1-3 Complete: {overall_missing:.1f}% missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9abb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4-5: Feature Engineering - Extract key features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 4-5: FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 64\n",
    "features, labels = [], []\n",
    "feature_names = []\n",
    "\n",
    "print(\"ðŸ”„ Extracting features from images...\")\n",
    "\n",
    "for category in categories:\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    category_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"Processing {category}: {len(category_files)} images\")\n",
    "    \n",
    "    for fname in category_files[:50]: \n",
    "        fpath = os.path.join(category_path, fname)\n",
    "        try:\n",
    "            img = Image.open(fpath).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "            arr = np.array(img)\n",
    "            \n",
    "            # Color features\n",
    "            mean_rgb = arr.mean(axis=(0,1))  # Mean RGB values\n",
    "            std_rgb = arr.std(axis=(0,1))   # Standard deviation RGB\n",
    "            \n",
    "            # Simple texture features \n",
    "            gray = np.mean(arr, axis=2)  # Convert to grayscale\n",
    "            edges = np.abs(np.diff(gray, axis=0)).sum() + np.abs(np.diff(gray, axis=1)).sum()\n",
    "            \n",
    "            # Brightness and contrast\n",
    "            brightness = np.mean(gray)\n",
    "            contrast = np.std(gray)\n",
    "            \n",
    "            # Combine features\n",
    "            feature_vector = np.concatenate([\n",
    "                mean_rgb,      # 3 features\n",
    "                std_rgb,       # 3 features  \n",
    "                [edges, brightness, contrast]  # 3 features\n",
    "            ])\n",
    "            \n",
    "            features.append(feature_vector)\n",
    "            labels.append(category)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Extraction Results:\")\n",
    "print(f\"   Features extracted: {features.shape[1]} per image\")\n",
    "print(f\"   Total samples: {features.shape[0]}\")\n",
    "print(f\"   Feature vector: [R_mean, G_mean, B_mean, R_std, G_std, B_std, edges, brightness, contrast]\")\n",
    "\n",
    "# Feature names for interpretation\n",
    "feature_names = ['R_mean', 'G_mean', 'B_mean', 'R_std', 'G_std', 'B_std', 'edges', 'brightness', 'contrast']\n",
    "\n",
    "print(f\"\\nâœ… Feature engineering complete!\")\n",
    "print(f\"   Categories: {np.unique(labels)}\")\n",
    "print(f\"   Samples per category: {[np.sum(labels == cat) for cat in np.unique(labels)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Evaluate feature impact\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 6: FEATURE IMPACT EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"ðŸ¤– Training Random Forest classifier...\")\n",
    "clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "scores = cross_val_score(clf, features, labels, cv=3)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Cross-Validation Results:\")\n",
    "print(f\"   Individual fold scores: {scores}\")\n",
    "print(f\"   Mean accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "# Feature importance analysis\n",
    "clf.fit(features, labels)\n",
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Feature Importance Ranking:\")\n",
    "importance_pairs = list(zip(feature_names, feature_importance))\n",
    "importance_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (name, importance) in enumerate(importance_pairs):\n",
    "    print(f\"   {i+1:2d}. {name:12s}: {importance:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… Task 6 Complete:\")\n",
    "print(f\"   Model accuracy: {scores.mean():.1%}\")\n",
    "print(f\"   Top features: {importance_pairs[0][0]}, {importance_pairs[1][0]}, {importance_pairs[2][0]}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09326a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional dataset visualization - Distribution by category\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=df, x='Category', y='Valid_Images', palette='viridis')\n",
    "plt.title('Number of Valid Images per Category', fontsize=14)\n",
    "plt.xlabel('Eye Disease Category', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart showing proportions of valid images\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(df['Valid_Images'], \n",
    "        labels=df['Category'], \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90,\n",
    "        colors=sns.color_palette('pastel'))\n",
    "plt.title('Proportion of Valid Images by Category', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56992ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images from each category\n",
    "import cv2\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "for i, category in enumerate(categories[:4]):\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    image_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if image_files:\n",
    "        img_path = os.path.join(category_path, image_files[0])\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                axes[i//2, i%2].imshow(img_rgb)\n",
    "                axes[i//2, i%2].set_title(category, fontsize=12)\n",
    "                axes[i//2, i%2].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[i//2, i%2].text(0.5, 0.5, f'Error loading\\n{category}', \n",
    "                                ha='center', va='center', transform=axes[i//2, i%2].transAxes)\n",
    "            axes[i//2, i%2].set_title(category, fontsize=12)\n",
    "\n",
    "plt.suptitle('Sample Images from Each Category', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8008a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average RGB channel intensity for each category\n",
    "channel_data = []\n",
    "\n",
    "for category in categories:\n",
    "\tcategory_path = os.path.join(dataset_path, category)\n",
    "\timage_files = [f for f in os.listdir(category_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\t# Sample up to 50 images per category for speed\n",
    "\tsample_files = image_files[:50] if len(image_files) > 50 else image_files\n",
    "\n",
    "\tfor image_file in sample_files:\n",
    "\t\timg_path = os.path.join(category_path, image_file)\n",
    "\t\ttry:\n",
    "\t\t\timg = cv2.imread(img_path)\n",
    "\t\t\tif img is not None:\n",
    "\t\t\t\timg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\t\t\t\tr_mean = img_rgb[:, :, 0].mean()\n",
    "\t\t\t\tg_mean = img_rgb[:, :, 1].mean()\n",
    "\t\t\t\tb_mean = img_rgb[:, :, 2].mean()\n",
    "\t\t\t\tchannel_data.append({'category': category, 'channel': 'Red', 'value': r_mean})\n",
    "\t\t\t\tchannel_data.append({'category': category, 'channel': 'Green', 'value': g_mean})\n",
    "\t\t\t\tchannel_data.append({'category': category, 'channel': 'Blue', 'value': b_mean})\n",
    "\t\texcept Exception:\n",
    "\t\t\tcontinue\n",
    "\n",
    "channel_df = pd.DataFrame(channel_data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=channel_df, x='category', y='value', hue='channel', palette=['red', 'green', 'blue'])\n",
    "plt.title('Average RGB Channel Intensity by Category', fontsize=14)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.ylabel('Pixel Intensity', fontsize=12)\n",
    "plt.legend(title='Color Channel')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632571cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10: Split Data and Train Models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "data_dir = \"dataset\"\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10  # You can increase for better performance\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb80fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 11: Cross-Validation and Model Evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.save(\"eye_disease_model.h5\")\n",
    "print(\"âœ… Model saved as eye_disease_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
